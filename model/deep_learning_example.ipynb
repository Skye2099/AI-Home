{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45ba5c2c-d3ed-4be8-ad81-50e5dc290fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import MSELoss, BCELoss, CrossEntropyLoss, NLLLoss\n",
    "from torch.utils.data import TensorDataset, Dataset, DataLoader, random_split\n",
    "from torchvision import transforms\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from tqdm import tqdm\n",
    "from schedulers import *\n",
    "import copy\n",
    "\n",
    "\n",
    "\n",
    "def load_methylation_pkl(files):    \n",
    "    '''\n",
    "    Load methylation data from csv file.\n",
    "\n",
    "    Note: We set nrows=5000 for test.\n",
    "    If you want to use full data, it is recommended to read csv file by chunks \n",
    "    or other methods since the csv file is very large.\n",
    "    Note the memory usage when you read csv file.\n",
    "\n",
    "    We fill nan with 0, you can try other methods.\n",
    "    '''\n",
    "    import joblib\n",
    "\n",
    "    methylation = np.concatenate([joblib.load(file) for file in files], axis= 0)\n",
    "    # methylation = pd.read_csv(methy_dir, sep=',', index_col=0, nrows=50000)\n",
    "#     methylation.fillna(0, inplace=True)\n",
    "    # methylation = methylation.values.T.astype(np.float16)\n",
    "    \n",
    "#     methylation = np.nan_to_num(methylation, nan = 0)\n",
    "    return methylation\n",
    "\n",
    "\n",
    "disease_mapping = {\n",
    "  'control': 0,\n",
    "  \"Alzheimer's disease\": 1,\n",
    "  \"Graves' disease\": 2,\n",
    "  \"Huntington's disease\": 3,\n",
    "  \"Parkinson's disease\": 4,\n",
    "  'rheumatoid arthritis': 5,\n",
    "  'schizophrenia': 6,\n",
    "  \"Sjogren's syndrome\": 7,\n",
    "  'stroke': 8,\n",
    "  'type 2 diabetes': 9\n",
    "}\n",
    "sample_type_mapping = {'control': 0, 'disease tissue': 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02b36973-9e3b-4da3-93e8-ddb3aeb31f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_idmap(idmap_dir):\n",
    "    idmap = pd.read_csv(idmap_dir, sep=',')\n",
    "    age = idmap.age.to_numpy()\n",
    "    age = age.astype(np.float16)\n",
    "    sample_type = idmap.sample_type.replace(sample_type_mapping)\n",
    "    return age, sample_type\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98207218-f105-4d40-9278-6588c977f4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "idmap_train_dir = '/opt/tml/tmp/dataphin-data/user/wangshulin/天池比赛/train/trainmap.csv'\n",
    "idmap_test_dir = '/opt/tml/tmp/dataphin-data/user/wangshulin/天池比赛/test/testmap.csv'\n",
    "methy_train_dir = '/opt/tml/tmp/dataphin-data/user/wangshulin/天池比赛/train'\n",
    "methy_test_dir = '/opt/tml/tmp/dataphin-data/user/wangshulin/天池比赛/test'\n",
    "\n",
    "age, sample_type = load_idmap(idmap_train_dir)\n",
    "age = [[i] for i in age]\n",
    "indices = np.arange(len(age))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70526f18-5f29-4338-8482-0bb5ea01ac17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载 feature_select 特征\n",
    "output_filename = '/root/notebook/model_code/dna/data/pearsonr/methylation_4W9.pkl'\n",
    "\n",
    "methylation = joblib.load(output_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "931ea60e-3605-4efb-9318-dc2650a7c810",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分成训练集和验证集\n",
    "methylation = methylation.to_numpy()\n",
    "\n",
    "[indices_train, indices_valid, age_train,\n",
    "age_valid] = train_test_split(indices, age, test_size=0.3, random_state= 0)\n",
    "\n",
    "methylation_train, methylation_valid = methylation[\n",
    "indices_train], methylation[indices_valid]\n",
    "\n",
    "sample_type_train, sample_type_valid = sample_type[\n",
    "indices_train], sample_type[indices_valid]\n",
    "\n",
    "feature_size = methylation_train.shape[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1cc9ebf2-80b6-4838-a9ee-ae4f9f1dd61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "else:\n",
    "    device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c27982fa-6124-42e6-ad31-589228909576",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataset.TensorDataset object at 0x7fb406fe9b10>\n"
     ]
    }
   ],
   "source": [
    "# 根据Tensor创建数据集\n",
    "\n",
    "from sklearn import datasets \n",
    "# iris = datasets.load_iris()\n",
    "ds_train = TensorDataset(torch.tensor(methylation_train, dtype=torch.float32).to(device),torch.tensor(age_train,dtype=torch.float32))\n",
    "ds_valid = TensorDataset(torch.tensor(methylation_valid,dtype=torch.float32).to(device),torch.tensor(age_valid,dtype=torch.float32))\n",
    "\n",
    "\n",
    "# 分割成训练集和预测集\n",
    "# n_train = int(len(methylation)*0.8)\n",
    "# n_valid = len(methylation) - n_train\n",
    "# ds_train,ds_valid = random_split(methylation,[n_train,n_valid])\n",
    "\n",
    "print(ds_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7498af95-27a2-4c1f-98a3-7bee0348f57f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.4138, -2.0898, -0.7354,  ..., -4.6914, -6.1641, -3.3145],\n",
      "        [-2.6328, -1.9727, -1.9365,  ..., -5.0938, -5.7734, -3.2559],\n",
      "        [-0.7349,  0.4641, -0.3262,  ..., -5.4922, -9.2109, -3.5078],\n",
      "        ...,\n",
      "        [-0.8901,  0.2249,  0.2168,  ..., -6.8125, -9.2109, -3.5078],\n",
      "        [-2.0117, -1.3428, -0.6147,  ..., -4.9414, -6.8125, -3.0527],\n",
      "        [-2.7676, -1.8828, -0.8853,  ..., -5.2734, -9.2109, -2.6328]],\n",
      "       device='cuda:0') torch.Size([50553]) tensor([82.])\n"
     ]
    }
   ],
   "source": [
    "# 使用DataLoader加载数据集\n",
    "dl_train,dl_valid = DataLoader(ds_train,batch_size = 128),DataLoader(ds_valid,batch_size = 128)\n",
    "\n",
    "for features,labels in dl_train:\n",
    "    print(features,features[0].shape,labels[0])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9efc8122-a581-403b-a644-f34520081e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, dropout_p=0.1, binary=False):\n",
    "        super(DNN, self).__init__()\n",
    "        self.topology = [input_size] + hidden_size + [output_size]\n",
    "        fc_layers = [nn.Linear(self.topology[i], self.topology[i+1]) for i in range(len(self.topology)-1)]\n",
    "        for layer in fc_layers:\n",
    "            nn.init.kaiming_uniform_(layer.weight)\n",
    "#         fc_net = [nn.Sequential(i, nn.ReLU(), nn.Dropout(dropout_p)) for i in fc_layers]\n",
    "        fc_net = [nn.Sequential(i, nn.ReLU()) for i in fc_layers]\n",
    "        if binary:\n",
    "            out_layer = nn.Sigmoid()\n",
    "            fc_net.append(out_layer)\n",
    "        self.dnn = nn.Sequential(*fc_net)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.dnn(x)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "19fd5952-a2a4-4531-9013-811594c80b06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DNN(\n",
       "  (dnn): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): Linear(in_features=50553, out_features=1024, bias=True)\n",
       "      (1): ReLU()\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Linear(in_features=1024, out_features=512, bias=True)\n",
       "      (1): ReLU()\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): Linear(in_features=512, out_features=256, bias=True)\n",
       "      (1): ReLU()\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): Linear(in_features=256, out_features=128, bias=True)\n",
       "      (1): ReLU()\n",
       "    )\n",
       "    (4): Sequential(\n",
       "      (0): Linear(in_features=128, out_features=64, bias=True)\n",
       "      (1): ReLU()\n",
       "    )\n",
       "    (5): Sequential(\n",
       "      (0): Linear(in_features=64, out_features=32, bias=True)\n",
       "      (1): ReLU()\n",
       "    )\n",
       "    (6): Sequential(\n",
       "      (0): Linear(in_features=32, out_features=16, bias=True)\n",
       "      (1): ReLU()\n",
       "    )\n",
       "    (7): Sequential(\n",
       "      (0): Linear(in_features=16, out_features=8, bias=True)\n",
       "      (1): ReLU()\n",
       "    )\n",
       "    (8): Sequential(\n",
       "      (0): Linear(in_features=8, out_features=4, bias=True)\n",
       "      (1): ReLU()\n",
       "    )\n",
       "    (9): Sequential(\n",
       "      (0): Linear(in_features=4, out_features=1, bias=True)\n",
       "      (1): ReLU()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = DNN(50553, hidden_size=[1024,512,256,128,64,32,16,8,4], output_size=1, dropout_p=0.1).to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c33c41b1-98f7-4ad6-afd3-1b6889a6bc95",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(self, model, val_dataloader, n_epoch=100, optimizer=torch.optim.Adam, lr=1e-3, loss_fn=nn.MSELoss()):\n",
    "        self.model = model\n",
    "        self.val_dataloader = val_dataloader\n",
    "        self.n_epoch = n_epoch\n",
    "        self.loss_fn = loss_fn\n",
    "        self.optimizer = optimizer(model.parameters(), lr=lr)\n",
    "        self.scheduler = ReduceLROnPlateau(self.optimizer, mode='min', factor=0.1, patience=1000,verbose = True)\n",
    "\n",
    "\n",
    "    def train_loop(self, train_dataloader, metric=0, verbose=True):\n",
    "        self.model.train()\n",
    "\n",
    "        total_loss = 0.\n",
    "\n",
    "        for i,(X,y) in enumerate(train_dataloader):\n",
    "            if torch.cuda.is_available():\n",
    "                X = X.cuda()\n",
    "                y = y.cuda()\n",
    "            y_pred = self.model(X)\n",
    "            self.optimizer.zero_grad()\n",
    "            loss = self.loss_fn(y_pred, y)\n",
    "\n",
    "            loss.backward() # loss 是个grad的tensor,获取数值需要loss.item()\n",
    "            self.optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            self.scheduler.step(loss) # 每个epoch/batch 更新一次lr\n",
    "        \n",
    "        epoch_loss = total_loss/(i+1)\n",
    "\n",
    "        return epoch_loss\n",
    "\n",
    "\n",
    "    def val_loop(self, val_dataloader):\n",
    "        self.model.eval()\n",
    "\n",
    "        epoch_loss = 0.\n",
    "        with torch.no_grad():\n",
    "            for i,(X,y) in enumerate(val_dataloader):\n",
    "                if torch.cuda.is_available():\n",
    "                    X = X.cuda()\n",
    "                    y = y.cuda()\n",
    "\n",
    "                pred = self.model(X)\n",
    "                loss = self.loss_fn(pred, y)\n",
    "                epoch_loss += loss.item()\n",
    "\n",
    "            return epoch_loss/(i+1)\n",
    "\n",
    "    # test_dataloader should be wiht no y label             \n",
    "    def test_loop(self, test_dataloader):\n",
    "        self.model.eval()\n",
    "\n",
    "        y_pred = []\n",
    "        for i,batch_data in enumerate(test_dataloader):\n",
    "            # TODO\n",
    "            X = batch_data # or batch_data[0]\n",
    "\n",
    "        \n",
    "    def fit(self, train_dataloader, verbose=True):\n",
    "        for epoch in range(self.n_epoch):\n",
    "            train_loss = self.train_loop(train_dataloader)\n",
    "            val_loss = self.val_loop(self.val_dataloader)\n",
    "            print(f'epoch_{epoch} train_loss: {train_loss},val_loss:{val_loss}')     \n",
    "            \n",
    "            if verbose:\n",
    "                current_lr = self.optimizer.param_groups[0]['lr']\n",
    "                print(f'Epoch {epoch}: Learning Rate = {current_lr}')\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "80e1aa9e-0ce9-4461-8dbc-400dae343de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "DNN_trainer=Trainer(model, val_dataloader=dl_valid, n_epoch=1000, optimizer=torch.optim.AdamW, lr=0.001, loss_fn=nn.MSELoss())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c44dcc5b-64b4-459c-b949-df9b6977ae51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_0 train_loss: 3517.6009999150815,val_loss:3573.098742675781\n",
      "Epoch 0: Learning Rate = 0.001\n",
      "epoch_1 train_loss: 3517.6009999150815,val_loss:3573.098742675781\n",
      "Epoch 1: Learning Rate = 0.001\n",
      "epoch_2 train_loss: 3517.6009999150815,val_loss:3573.098742675781\n",
      "Epoch 2: Learning Rate = 0.001\n",
      "epoch_3 train_loss: 3517.6009999150815,val_loss:3573.098742675781\n",
      "Epoch 3: Learning Rate = 0.001\n",
      "epoch_4 train_loss: 3517.6009999150815,val_loss:3573.098742675781\n",
      "Epoch 4: Learning Rate = 0.001\n",
      "epoch_5 train_loss: 3517.6009999150815,val_loss:3573.098742675781\n",
      "Epoch 5: Learning Rate = 0.001\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-9c775ae7eaa2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mDNN_trainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdl_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-18-6e60f53a1374>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, train_dataloader, verbose)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m             \u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'epoch_{epoch} train_loss: {train_loss},val_loss:{val_loss}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-18-6e60f53a1374>\u001b[0m in \u001b[0;36mtrain_loop\u001b[0;34m(self, train_dataloader, metric, verbose)\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m             \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 每个epoch/batch 更新一次lr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "DNN_trainer.fit(dl_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "dd565c08-afce-41d2-ac07-2d605f27ee2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class fc(nn.Module):\n",
    "#     def __init__(self, \n",
    "#                  input_size, \n",
    "#                  hidden_sizes, \n",
    "#                  output_size, \n",
    "#                  dropout, \n",
    "#                  if_bn=True):\n",
    "#         super().__init__()\n",
    "        \n",
    "#         torch.manual_seed(123)\n",
    "#         torch.cuda.manual_seed(123)\n",
    "#         self.input_layer = nn.Linear(input_size, hidden_sizes[0])\n",
    "#         self.hidden_layers = nn.ModuleList([nn.Linear(hidden_sizes[i], hidden_sizes[i+1]) for i in range(len(hidden_sizes)-1)])\n",
    "#         self.bn_layers = nn.ModuleList([nn.BatchNorm1d(hidden_sizes[i+1]) for i in range(len(hidden_sizes)-1)])\n",
    "        \n",
    "#         self.dp = nn.Dropout(dropout)\n",
    "#         self.output_layer = nn.Linear(hidden_sizes[-1], output_size)\n",
    "\n",
    "#         torch.nn.init.kaiming_uniform(self.input_layer.weight)\n",
    "#         [torch.nn.init.kaiming_uniform_(layer.weight) for layer in self.hidden_layers]\n",
    "#         torch.nn.init.kaiming_uniform(self.output_layer.weight)\n",
    "#         self.if_bn = if_bn\n",
    "        \n",
    "#     def forward(self, x):\n",
    "#         x = nn.GELU()(self.input_layer(x))\n",
    "\n",
    "#         if len(x.shape) == 2:\n",
    "#             for l,bn in zip(self.hidden_layers,self.bn_layers):\n",
    "#                 x = l(x)\n",
    "#                 if self.if_bn:\n",
    "#                     x = bn(x)\n",
    "#                 else:\n",
    "#                     pass\n",
    "#                 x = nn.GELU()(x)\n",
    "#                 x = self.dp(x)\n",
    "        \n",
    "#         elif len(x.shape) == 3:\n",
    "#             for l,bn in zip(self.hidden_layers,self.bn_layers):\n",
    "#                 x = l(x)\n",
    "#                 if self.if_bn:\n",
    "#                     x = x.permute(0,2,1)\n",
    "#                     x = bn(x)\n",
    "#                     x = x.permute(0,2,1)\n",
    "#                 else:\n",
    "#                     pass\n",
    "#                 x = nn.GELU()(x)\n",
    "#                 x = self.dp(x)\n",
    "#         else:\n",
    "#             print('input size needs to be 2d or 3d')\n",
    "#             raise\n",
    "#         emb = x\n",
    "#         x = self.output_layer(x)\n",
    "#         return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "a3fc62cc-673e-47d1-b020-eeecf56c2d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Model(nn.Module):\n",
    "#     def __init__(self, num_features, num_targets, hidden_sizes):\n",
    "#         super(Model, self).__init__()\n",
    "#         self.num_features = num_features\n",
    "#         self.num_targets = num_targets\n",
    "#         self.hidden_sizes = hidden_sizes\n",
    "#         self.dropout = 0.2\n",
    "#         self.fc = fc(input_size = num_features,\n",
    "#                      hidden_sizes = self.hidden_sizes,\n",
    "#                      output_size = self.num_targets,\n",
    "#                      dropout = self.dropout,\n",
    "#                      if_bn = False)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         out = self.fc(x)\n",
    "# #         out = torch.sigmoid(out)\n",
    "\n",
    "#         return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "af90a837-b5e0-4dae-a25a-ef0e14fd865f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:19: UserWarning: nn.init.kaiming_uniform is now deprecated in favor of nn.init.kaiming_uniform_.\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:21: UserWarning: nn.init.kaiming_uniform is now deprecated in favor of nn.init.kaiming_uniform_.\n"
     ]
    }
   ],
   "source": [
    "model = Model(num_features = 50553, num_targets = 1, hidden_sizes = [1024,512,256,128,64,32,16,8,4,1]).to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "74af6e01-0fd7-47a4-acf9-f93cb47be76b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "4deb8ac9-4169-4d25-bb87-5689786af128",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================================================\n",
      "Layer (type:depth-idx)                   Param #\n",
      "=================================================================\n",
      "├─fc: 1-1                                --\n",
      "|    └─Linear: 2-1                       51,767,296\n",
      "|    └─ModuleList: 2-2                   --\n",
      "|    |    └─Linear: 3-1                  524,800\n",
      "|    |    └─Linear: 3-2                  131,328\n",
      "|    |    └─Linear: 3-3                  32,896\n",
      "|    |    └─Linear: 3-4                  8,256\n",
      "|    |    └─Linear: 3-5                  2,080\n",
      "|    |    └─Linear: 3-6                  528\n",
      "|    |    └─Linear: 3-7                  136\n",
      "|    |    └─Linear: 3-8                  36\n",
      "|    |    └─Linear: 3-9                  5\n",
      "|    └─ModuleList: 2-3                   --\n",
      "|    |    └─BatchNorm1d: 3-10            1,024\n",
      "|    |    └─BatchNorm1d: 3-11            512\n",
      "|    |    └─BatchNorm1d: 3-12            256\n",
      "|    |    └─BatchNorm1d: 3-13            128\n",
      "|    |    └─BatchNorm1d: 3-14            64\n",
      "|    |    └─BatchNorm1d: 3-15            32\n",
      "|    |    └─BatchNorm1d: 3-16            16\n",
      "|    |    └─BatchNorm1d: 3-17            8\n",
      "|    |    └─BatchNorm1d: 3-18            2\n",
      "|    └─Dropout: 2-4                      --\n",
      "|    └─Linear: 2-5                       2\n",
      "=================================================================\n",
      "Total params: 52,469,405\n",
      "Trainable params: 52,469,405\n",
      "Non-trainable params: 0\n",
      "=================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "=================================================================\n",
       "Layer (type:depth-idx)                   Param #\n",
       "=================================================================\n",
       "├─fc: 1-1                                --\n",
       "|    └─Linear: 2-1                       51,767,296\n",
       "|    └─ModuleList: 2-2                   --\n",
       "|    |    └─Linear: 3-1                  524,800\n",
       "|    |    └─Linear: 3-2                  131,328\n",
       "|    |    └─Linear: 3-3                  32,896\n",
       "|    |    └─Linear: 3-4                  8,256\n",
       "|    |    └─Linear: 3-5                  2,080\n",
       "|    |    └─Linear: 3-6                  528\n",
       "|    |    └─Linear: 3-7                  136\n",
       "|    |    └─Linear: 3-8                  36\n",
       "|    |    └─Linear: 3-9                  5\n",
       "|    └─ModuleList: 2-3                   --\n",
       "|    |    └─BatchNorm1d: 3-10            1,024\n",
       "|    |    └─BatchNorm1d: 3-11            512\n",
       "|    |    └─BatchNorm1d: 3-12            256\n",
       "|    |    └─BatchNorm1d: 3-13            128\n",
       "|    |    └─BatchNorm1d: 3-14            64\n",
       "|    |    └─BatchNorm1d: 3-15            32\n",
       "|    |    └─BatchNorm1d: 3-16            16\n",
       "|    |    └─BatchNorm1d: 3-17            8\n",
       "|    |    └─BatchNorm1d: 3-18            2\n",
       "|    └─Dropout: 2-4                      --\n",
       "|    └─Linear: 2-5                       2\n",
       "=================================================================\n",
       "Total params: 52,469,405\n",
       "Trainable params: 52,469,405\n",
       "Non-trainable params: 0\n",
       "================================================================="
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "5d6febcb-6002-49bb-a220-aeabb9235fa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================================================\n",
      "Layer (type:depth-idx)                   Param #\n",
      "=================================================================\n",
      "├─Sequential: 1-1                        --\n",
      "|    └─Sequential: 2-1                   --\n",
      "|    |    └─Linear: 3-1                  51,767,296\n",
      "|    |    └─ReLU: 3-2                    --\n",
      "|    |    └─Dropout: 3-3                 --\n",
      "|    └─Sequential: 2-2                   --\n",
      "|    |    └─Linear: 3-4                  524,800\n",
      "|    |    └─ReLU: 3-5                    --\n",
      "|    |    └─Dropout: 3-6                 --\n",
      "|    └─Sequential: 2-3                   --\n",
      "|    |    └─Linear: 3-7                  131,328\n",
      "|    |    └─ReLU: 3-8                    --\n",
      "|    |    └─Dropout: 3-9                 --\n",
      "|    └─Sequential: 2-4                   --\n",
      "|    |    └─Linear: 3-10                 32,896\n",
      "|    |    └─ReLU: 3-11                   --\n",
      "|    |    └─Dropout: 3-12                --\n",
      "|    └─Sequential: 2-5                   --\n",
      "|    |    └─Linear: 3-13                 8,256\n",
      "|    |    └─ReLU: 3-14                   --\n",
      "|    |    └─Dropout: 3-15                --\n",
      "|    └─Sequential: 2-6                   --\n",
      "|    |    └─Linear: 3-16                 2,080\n",
      "|    |    └─ReLU: 3-17                   --\n",
      "|    |    └─Dropout: 3-18                --\n",
      "|    └─Sequential: 2-7                   --\n",
      "|    |    └─Linear: 3-19                 528\n",
      "|    |    └─ReLU: 3-20                   --\n",
      "|    |    └─Dropout: 3-21                --\n",
      "|    └─Sequential: 2-8                   --\n",
      "|    |    └─Linear: 3-22                 136\n",
      "|    |    └─ReLU: 3-23                   --\n",
      "|    |    └─Dropout: 3-24                --\n",
      "|    └─Sequential: 2-9                   --\n",
      "|    |    └─Linear: 3-25                 36\n",
      "|    |    └─ReLU: 3-26                   --\n",
      "|    |    └─Dropout: 3-27                --\n",
      "|    └─Sequential: 2-10                  --\n",
      "|    |    └─Linear: 3-28                 5\n",
      "|    |    └─ReLU: 3-29                   --\n",
      "|    |    └─Dropout: 3-30                --\n",
      "=================================================================\n",
      "Total params: 52,467,361\n",
      "Trainable params: 52,467,361\n",
      "Non-trainable params: 0\n",
      "=================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "=================================================================\n",
       "Layer (type:depth-idx)                   Param #\n",
       "=================================================================\n",
       "├─Sequential: 1-1                        --\n",
       "|    └─Sequential: 2-1                   --\n",
       "|    |    └─Linear: 3-1                  51,767,296\n",
       "|    |    └─ReLU: 3-2                    --\n",
       "|    |    └─Dropout: 3-3                 --\n",
       "|    └─Sequential: 2-2                   --\n",
       "|    |    └─Linear: 3-4                  524,800\n",
       "|    |    └─ReLU: 3-5                    --\n",
       "|    |    └─Dropout: 3-6                 --\n",
       "|    └─Sequential: 2-3                   --\n",
       "|    |    └─Linear: 3-7                  131,328\n",
       "|    |    └─ReLU: 3-8                    --\n",
       "|    |    └─Dropout: 3-9                 --\n",
       "|    └─Sequential: 2-4                   --\n",
       "|    |    └─Linear: 3-10                 32,896\n",
       "|    |    └─ReLU: 3-11                   --\n",
       "|    |    └─Dropout: 3-12                --\n",
       "|    └─Sequential: 2-5                   --\n",
       "|    |    └─Linear: 3-13                 8,256\n",
       "|    |    └─ReLU: 3-14                   --\n",
       "|    |    └─Dropout: 3-15                --\n",
       "|    └─Sequential: 2-6                   --\n",
       "|    |    └─Linear: 3-16                 2,080\n",
       "|    |    └─ReLU: 3-17                   --\n",
       "|    |    └─Dropout: 3-18                --\n",
       "|    └─Sequential: 2-7                   --\n",
       "|    |    └─Linear: 3-19                 528\n",
       "|    |    └─ReLU: 3-20                   --\n",
       "|    |    └─Dropout: 3-21                --\n",
       "|    └─Sequential: 2-8                   --\n",
       "|    |    └─Linear: 3-22                 136\n",
       "|    |    └─ReLU: 3-23                   --\n",
       "|    |    └─Dropout: 3-24                --\n",
       "|    └─Sequential: 2-9                   --\n",
       "|    |    └─Linear: 3-25                 36\n",
       "|    |    └─ReLU: 3-26                   --\n",
       "|    |    └─Dropout: 3-27                --\n",
       "|    └─Sequential: 2-10                  --\n",
       "|    |    └─Linear: 3-28                 5\n",
       "|    |    └─ReLU: 3-29                   --\n",
       "|    |    └─Dropout: 3-30                --\n",
       "=================================================================\n",
       "Total params: 52,467,361\n",
       "Trainable params: 52,467,361\n",
       "Non-trainable params: 0\n",
       "================================================================="
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f5a8da-6517-4a2f-be21-fa78a512232d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "058522bc-7a8d-4969-8cc1-5cb8be0b6cf9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa4dfc25-bf65-4442-a0d8-aae461ce5932",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
